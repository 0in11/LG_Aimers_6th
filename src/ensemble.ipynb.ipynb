{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "\n",
    "\n",
    "# 학습 곡선 시각화화\n",
    "def plot_learning_curves(train_scores, eval_scores):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_scores, label='Train AUC')\n",
    "    plt.plot(eval_scores, label='Validation AUC')\n",
    "    plt.title('Learning Curves')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('AUC Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('learning_curves.png')\n",
    "    plt.close()\n",
    "\n",
    "# 오버피팅 분석\n",
    "def analyze_overfitting(train_scores, eval_scores, val_scores, predictions):\n",
    "    print(\"\\n=== 오버피팅 분석 ===\")\n",
    "\n",
    "    # 검증 점수 안정성\n",
    "    val_std = np.std(val_scores)\n",
    "    print(f\"검증 점수 평균: {np.mean(val_scores):.4f}\")\n",
    "    print(f\"검증 점수 표준편차: {val_std:.4f}\")\n",
    "    print(f\"검증 표준편차 위험도: {'높음' if val_std > 0.02 else '낮음'}\")\n",
    "\n",
    "    # 학습-검증 점수 차이\n",
    "    score_gap = np.mean(train_scores) - np.mean(eval_scores)\n",
    "    print(f\"\\n학습-검증 점수 차이: {score_gap:.4f}\")\n",
    "    print(f\"점수 차이 위험도: {'높음' if score_gap > 0.05 else '낮음'}\")\n",
    "\n",
    "    # 예측 분포 확인\n",
    "    extreme_preds = np.sum((predictions < 0.1) | (predictions > 0.9)) / len(predictions)\n",
    "    print(f\"극단적 예측 비율: {extreme_preds:.2%}\")\n",
    "    print(f\"극단적 예측 위험도: {'높음' if extreme_preds > 0.3 else '낮음'}\")\n",
    "\n",
    "    # 모델 안정성\n",
    "    score_range = max(val_scores) - min(val_scores)\n",
    "    print(f\"모델간 성능 범위: {score_range:.4f}\")\n",
    "    print(f\"모델 안정성 위험도: {'높음' if score_range > 0.03 else '낮음'}\")\n",
    "\n",
    "    # 종합 위험도 점수 (0~1, 높을수록 위험)\n",
    "    risk_score = (\n",
    "        (val_std > 0.02) * 0.25 +\n",
    "        (score_gap > 0.05) * 0.25 +\n",
    "        (extreme_preds > 0.3) * 0.25 +\n",
    "        (score_range > 0.03) * 0.25\n",
    "    )\n",
    "\n",
    "    print(f\"\\n종합 오버피팅 위험도: {risk_score:.2f} (0~1)\")\n",
    "\n",
    "    return {\n",
    "        'val_std': val_std,\n",
    "        'score_gap': score_gap,\n",
    "        'extreme_preds': extreme_preds,\n",
    "        'score_range': score_range,\n",
    "        'risk_score': risk_score\n",
    "    }\n",
    "\n",
    "\n",
    "# XGBoost 최적 파라미터(optuna)\n",
    "def get_base_params():\n",
    "    base_params = {\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.01066843580150729,\n",
    "        'min_child_weight': 3,\n",
    "        'gamma': 2.4678454032083947,\n",
    "        'subsample': 0.6764633483838101,\n",
    "        'colsample_bytree': 0.9607914123554494,\n",
    "        'reg_alpha': 8.354654668642027,\n",
    "        'reg_lambda': 8.053982964153542,\n",
    "        'scale_pos_weight': 1.3632074855869183,\n",
    "        'random_state': 42,\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc'\n",
    "    }\n",
    "\n",
    "    # GPU 가속 설정\n",
    "    try:\n",
    "        if torch.cuda.is_available():\n",
    "            base_params.update({\"tree_method\": \"hist\", \"device\": \"cuda:0\"})\n",
    "        else:\n",
    "            base_params.update({\"tree_method\": \"hist\"})\n",
    "    except:\n",
    "        base_params.update({\"tree_method\": \"hist\"})\n",
    "        \n",
    "    return base_params\n",
    "\n",
    "\n",
    "# 다양한 시드와 파라미터 변화를 활용한 XGBoost 앙상블 모델\n",
    "def train_seed_stratified_ensemble(X, y, X_test, n_models=15, n_folds=5):\n",
    "    # 기본 최적 파라미터 \n",
    "    base_params = get_base_params()\n",
    "\n",
    "    # 다양성을 위한 파라미터 변화 범위\n",
    "    param_ranges = {\n",
    "        'max_depth': [-1, 0, 1],  # 최적값 근처에서 변화\n",
    "        'min_child_weight': [-1, 0, 1],\n",
    "        'gamma': [-0.2, 0, 0.2],  # 작은 변화\n",
    "        'subsample': [-0.03, 0, 0.03],  # 작은 변화\n",
    "        'colsample_bytree': [-0.02, 0, 0.02],  # 작은 변화\n",
    "        'reg_alpha': [-0.5, 0, 0.5],  # 소폭 변화\n",
    "        'reg_lambda': [-0.5, 0, 0.5],  # 소폭 변화\n",
    "        'scale_pos_weight': [-0.1, 0, 0.1]  # 소폭 변화\n",
    "    }\n",
    "\n",
    "    test_predictions = np.zeros((len(X_test), n_models))\n",
    "    oof_predictions = np.zeros(len(X))  # Out-of-fold 예측값 저장\n",
    "    val_scores = []\n",
    "    best_iterations = []\n",
    "    train_scores_all = []\n",
    "    eval_scores_all = []\n",
    "\n",
    "    print(f\"학습 시작 시간: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 각 모델별 파라미터와 시드 설정\n",
    "    for i in range(n_models):\n",
    "        # 기본 파라미터 복사\n",
    "        model_params = base_params.copy()\n",
    "\n",
    "        # 다양성을 위한 무작위 시드 설정\n",
    "        seed = (i * 111 + 42) % 10000\n",
    "        model_params['seed'] = seed\n",
    "        model_params['random_state'] = seed\n",
    "\n",
    "        # 파라미터 약간씩 변경하여 다양성 확보\n",
    "        print(f\"\\n====== 모델 {i+1}/{n_models} (시드: {seed}) ======\")\n",
    "        print(\"파라미터 변경:\")\n",
    "\n",
    "        for param, ranges in param_ranges.items():\n",
    "            # 정수형 파라미터\n",
    "            if param in ['max_depth', 'min_child_weight']:\n",
    "                change = np.random.choice(ranges)\n",
    "                if param in model_params:\n",
    "                    model_params[param] = max(1, model_params[param] + change)\n",
    "                    print(f\"  {param}: {base_params[param]} -> {model_params[param]}\")\n",
    "            # 실수형 파라미터\n",
    "            else:\n",
    "                if param in model_params:\n",
    "                    change = np.random.uniform(ranges[0], ranges[2])\n",
    "                    # 반올림하여 보기 좋게 표시\n",
    "                    original = model_params[param]\n",
    "                    model_params[param] = max(0.001, model_params[param] + change)\n",
    "                    print(f\"  {param}: {original:.6f} -> {model_params[param]:.6f}\")\n",
    "\n",
    "        # StratifiedKFold 정의\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "        fold_val_scores = []\n",
    "        fold_predictions = np.zeros((len(X_test), n_folds))\n",
    "\n",
    "        # 각 폴드별 학습\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "            dval = xgb.DMatrix(X_val, label=y_val)\n",
    "            dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "            # 학습 과정 저장을 위한 평가 결과 저장소\n",
    "            evals_result = {}\n",
    "\n",
    "            model = xgb.train(\n",
    "                model_params,\n",
    "                dtrain,\n",
    "                num_boost_round=5000,\n",
    "                evals=[(dtrain, 'train'), (dval, 'eval')],\n",
    "                early_stopping_rounds=50,\n",
    "                verbose_eval=100,\n",
    "                evals_result=evals_result\n",
    "            )\n",
    "\n",
    "            # 학습 곡선 데이터 저장 (첫 번째 폴드만)\n",
    "            if fold == 0:\n",
    "                train_scores = evals_result['train']['auc'][:model.best_iteration]\n",
    "                eval_scores = evals_result['eval']['auc'][:model.best_iteration]\n",
    "                train_scores_all.append(train_scores)\n",
    "                eval_scores_all.append(eval_scores)\n",
    "                best_iterations.append(model.best_iteration)\n",
    "\n",
    "            # Out-of-fold 예측\n",
    "            val_preds = model.predict(dval, iteration_range=(0, model.best_iteration+1))\n",
    "            oof_predictions[val_idx] = val_preds\n",
    "\n",
    "            # 검증 점수 계산\n",
    "            fold_val_score = roc_auc_score(y_val, val_preds)\n",
    "            fold_val_scores.append(fold_val_score)\n",
    "            print(f\"Fold {fold + 1} 검증 AUC: {fold_val_score:.4f}\")\n",
    "\n",
    "            # 테스트 예측\n",
    "            fold_predictions[:, fold] = model.predict(\n",
    "                dtest, iteration_range=(0, model.best_iteration+1)\n",
    "            )\n",
    "\n",
    "        # 폴드별 평균 검증 점수\n",
    "        mean_val_score = np.mean(fold_val_scores)\n",
    "        val_scores.append(mean_val_score)\n",
    "        print(f\"\\n모델 {i+1} 평균 검증 AUC: {mean_val_score:.4f}\")\n",
    "\n",
    "        # 테스트 예측값 (폴드 평균)\n",
    "        test_predictions[:, i] = np.mean(fold_predictions, axis=1)\n",
    "\n",
    "    # 학습 시간 계산\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"\\n총 학습 시간: {timedelta(seconds=int(train_time))}\")\n",
    "\n",
    "    # 모델별 성능 출력\n",
    "    print(\"\\n=== 개별 모델 성능 ===\")\n",
    "    for i, score in enumerate(val_scores):\n",
    "        print(f\"모델 {i+1} - 평균 검증 AUC: {score:.4f}\")\n",
    "\n",
    "    # 학습 곡선 분석을 위한 처리\n",
    "    min_length = min(len(scores) for scores in train_scores_all)\n",
    "    train_scores_aligned = np.array([scores[:min_length] for scores in train_scores_all])\n",
    "    eval_scores_aligned = np.array([scores[:min_length] for scores in eval_scores_all])\n",
    "    \n",
    "    # 평균 학습 곡선 계산\n",
    "    avg_train_scores = train_scores_aligned.mean(axis=0)\n",
    "    avg_eval_scores = eval_scores_aligned.mean(axis=0)\n",
    "\n",
    "    # 앙상블 방식 계산\n",
    "    # 1. 단순 평균\n",
    "    simple_avg_predictions = test_predictions.mean(axis=1)\n",
    "\n",
    "    # 2. 성능 가중치 기반 평균 (성능이 좋은 모델에 더 높은 가중치)\n",
    "    normalized_scores = np.array(val_scores) / np.sum(val_scores)\n",
    "    weighted_predictions = np.zeros(len(X_test))\n",
    "    for i in range(n_models):\n",
    "        weighted_predictions += normalized_scores[i] * test_predictions[:, i]\n",
    "\n",
    "    # 3. 상위 N개 모델만 사용하는 앙상블\n",
    "    top_n = max(3, n_models // 2)  # 상위 절반 또는 최소 3개\n",
    "    top_indices = np.argsort(val_scores)[-top_n:]\n",
    "    top_scores = np.array([val_scores[i] for i in top_indices])\n",
    "    top_weights = top_scores / np.sum(top_scores)\n",
    "\n",
    "    top_predictions = np.zeros(len(X_test))\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        top_predictions += top_weights[i] * test_predictions[:, idx]\n",
    "\n",
    "    # 예측 불확실성 분석\n",
    "    pred_std = test_predictions.std(axis=1)\n",
    "    high_uncertainty = np.percentile(pred_std, 90)\n",
    "    uncertainty_ratio = (pred_std > high_uncertainty).mean()\n",
    "\n",
    "    print(f\"\\n=== 앙상블 방식 비교 ===\")\n",
    "    print(f\"단순 평균 예측 분포: {simple_avg_predictions.mean():.4f} ± {simple_avg_predictions.std():.4f}\")\n",
    "    print(f\"가중치 평균 예측 분포: {weighted_predictions.mean():.4f} ± {weighted_predictions.std():.4f}\")\n",
    "    print(f\"상위 {top_n}개 모델 평균 예측 분포: {top_predictions.mean():.4f} ± {top_predictions.std():.4f}\")\n",
    "\n",
    "    # 오버피팅 분석 및 시각화\n",
    "    plot_learning_curves(avg_train_scores, avg_eval_scores)\n",
    "    overfitting_metrics = analyze_overfitting(avg_train_scores, avg_eval_scores,\n",
    "                                           val_scores, weighted_predictions)\n",
    "\n",
    "    # 최종 예측값 선택 (오버피팅 위험도에 따라)\n",
    "    if overfitting_metrics['risk_score'] < 0.25:\n",
    "        print(\"\\n가중치 기반 예측 사용 (오버피팅 위험 매우 낮음)\")\n",
    "        final_predictions = weighted_predictions\n",
    "    elif overfitting_metrics['risk_score'] < 0.5:\n",
    "        print(\"\\n상위 모델 앙상블 사용 (오버피팅 위험 낮음)\")\n",
    "        final_predictions = top_predictions\n",
    "    else:\n",
    "        print(\"\\n단순 평균 예측 사용 (오버피팅 위험 높음)\")\n",
    "        final_predictions = simple_avg_predictions\n",
    "\n",
    "    return final_predictions, pred_std, test_predictions, val_scores, oof_predictions\n",
    "\n",
    "\n",
    "# 예측 결과 저장\n",
    "def save_results(predictions, uncertainties, all_preds, test_ids):\n",
    "    # 기본 예측 결과 저장\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_ids,\n",
    "        'probability': predictions\n",
    "    })\n",
    "    submission.to_csv('xgb_diverse_ensemble_submission.csv', index=False)\n",
    "    print(\"예측 결과가 'xgb_diverse_ensemble_submission.csv'에 저장되었습니다.\")\n",
    "\n",
    "    # 상세 결과 저장 (불확실성 포함)\n",
    "    detailed_results = pd.DataFrame({\n",
    "        'ID': test_ids,\n",
    "        'predicted_probability': predictions,\n",
    "        'prediction_uncertainty': uncertainties,\n",
    "        'high_uncertainty': uncertainties > np.percentile(uncertainties, 90)\n",
    "    })\n",
    "    detailed_results.to_csv('xgb_diverse_ensemble_detailed.csv', index=False)\n",
    "    print(\"상세 예측 결과가 'xgb_diverse_ensemble_detailed.csv'에 저장되었습니다.\")\n",
    "\n",
    "    # 개별 모델 예측 저장\n",
    "    model_predictions = pd.DataFrame(all_preds,\n",
    "                                  columns=[f'model_{i+1}' for i in range(all_preds.shape[1])])\n",
    "    model_predictions.insert(0, 'ID', test_ids)\n",
    "    model_predictions.to_csv('xgb_diverse_individual_predictions.csv', index=False)\n",
    "    print(\"개별 모델 예측이 'xgb_diverse_individual_predictions.csv'에 저장되었습니다.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    print(\"데이터 로드 중...\")\n",
    "    try:      \n",
    "        # 특성과 타겟 분리\n",
    "        X = train_processed.drop(columns=[\"임신 성공 여부\"])\n",
    "        y = train_processed[\"임신 성공 여부\"]\n",
    "        \n",
    "        print(f\"학습 데이터 형태: {X.shape}\")\n",
    "        print(f\"테스트 데이터 형태: {test_processed.shape}\")\n",
    "        \n",
    "        # 앙상블 학습 및 예측\n",
    "        print(\"\\n앙상블 모델 학습 시작...\")\n",
    "        predictions, uncertainties, all_preds, scores, oof_preds = train_seed_stratified_ensemble(\n",
    "            X, y, test_processed, n_models=20, n_folds=5\n",
    "        )\n",
    "        \n",
    "        # OOF 점수 계산\n",
    "        oof_score = roc_auc_score(y, oof_preds)\n",
    "        print(f\"\\nOut-of-fold AUC: {oof_score:.4f}\")\n",
    "        \n",
    "        # 결과 저장\n",
    "        save_results(predictions, uncertainties, all_preds, test['ID'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
